# Sistema de Autoscaling con Kubernetes (GKE / AKS)

Sistema de demostraciÃ³n de autoscaling automÃ¡tico desplegado en Google Kubernetes Engine (GKE) o Azure Kubernetes Service (AKS) con infraestructura como cÃ³digo usando Pulumi.


Este proyecto implementa una arquitectura **Micro-Stack** basada en los principios del libro **"Infrastructure as Code: Dynamic Systems for the Cloud Age"** de Kief Morris.


## Principios de IaC Implementados

### CapÃ­tulo 1: Mentalidad de la Edad de Nube
- **Velocidad + Calidad**: Infraestructura reproducible = cambios rÃ¡pidos y seguros  
- **4 MÃ©tricas DORA**: Sistema preparado para CD (despliegues frecuentes, MTTR bajo)  
- **Piezas pequeÃ±as dÃ©bilmente acopladas**: Frontend, backend y DB independientes

### CapÃ­tulo 2: Principios de Infraestructura
- **Asumir sistemas no confiables**: Pods efÃ­meros con health checks y auto-healing  
- **Hacer todo reproducible**: Toda la infraestructura definida como cÃ³digo  
- **Cosas desechables (Ganado no Mascotas)**: Pods reemplazables automÃ¡ticamente  
- **Minimizar variaciÃ³n**: Node pools homogÃ©neos, todas las VMs son iguales

### CapÃ­tulo 3: Plataformas de Infraestructura
- **Modelo 3 capas**:
  - **IaaS**: AKS cluster, VNET, NSG (infrastructure-k8s-base)
  - **PaaS**: PostgreSQL, Node pools (infrastructure-k8s-db)
  - **Aplicaciones**: Frontend/Backend pods (infrastructure-k8s-deploy)

### CapÃ­tulo 4: Define Todo como CÃ³digo
- **Todo en VCS**: Git como fuente de verdad, todo versionado  
- **Declarativo**: Pulumi + Kubernetes manifiestos (idempotentes)  
- **GPL sobre DSL**: Pulumi con Python (no HCL/YAML puro)

### CapÃ­tulo 5: Micro-Stack Pattern
- **3 Pilas Independientes**:
  1. **k8s-base**: Infraestructura base (cluster AKS)
  2. **k8s-db**: Base de datos (ciclo de vida separado)
  3. **k8s-deploy**: Aplicaciones (frontend + backend)
- **Radio de explosiÃ³n limitado**: Cambios aislados por pila  
- **Ciclos de vida independientes**: Puedo reconstruir el cluster sin tocar la DB

## Estructura del Proyecto

```
sistema-autoscaling/
â”œâ”€â”€ infrastructure-k8s-base/       # Pila 1: AKS Cluster (IaaS)
â”‚   â”œâ”€â”€ __main__.py                # Cluster AKS con 3 node pools
â”‚   â”œâ”€â”€ Pulumi.yaml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ infrastructure-k8s-db/         # Pila 2: Base de Datos (Micro-stack)
â”‚   â”œâ”€â”€ __main__.py                # PostgreSQL Flexible Server
â”‚   â”œâ”€â”€ Pulumi.yaml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ infrastructure-k8s-deploy/     # Pila 3: Despliegue K8s (PaaS)
â”‚   â”œâ”€â”€ __main__.py                # Despliega backend y frontend
â”‚   â”œâ”€â”€ Pulumi.yaml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ k8s/                           # Manifiestos Kubernetes
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml        # Backend + HPA
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml        # Frontend + HPA + LoadBalancer
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ prometheus-grafana.yaml
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ backend/                       # CÃ³digo de la aplicaciÃ³n
â”‚   â”œâ”€â”€ app.py                     # Flask + PostgreSQL
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/                      # CÃ³digo del frontend
â”‚   â”œâ”€â”€ src/App.jsx                # React
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ nginx.conf
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ scripts/                       # Scripts de pruebas de carga
â”‚   â”œâ”€â”€ extreme-load.py
â”‚   â””â”€â”€ ultra-load.py
â”‚
â”œâ”€â”€ ARQUITECTURA-K8S.md            # DocumentaciÃ³n detallada
â””â”€â”€ README.md                      # Este archivo
```

## Despliegue Completo

### OpciÃ³n A: Despliegue Automatizado en GCP (Recomendado)

**Pre-requisitos**:
```bash
# Instalar gcloud CLI
curl https://sdk.cloud.google.com | bash
exec -l $SHELL

# Login a GCP
gcloud auth login
gcloud auth application-default login

# Configurar proyecto
gcloud config set project cpe-autoscaling-k8s

# Instalar Pulumi
curl -fsSL https://get.pulumi.com | sh

# Instalar kubectl
gcloud components install kubectl

# Instalar Docker
sudo apt-get update && sudo apt-get install docker.io -y

# Instalar plugin de autenticaciÃ³n GKE
gcloud components install gke-gcloud-auth-plugin
```

**Despliegue automatizado** (todos los pasos):
```bash
cd scripts

# Desplegar todo (cluster, DB, imÃ¡genes, apps)
bash gcp-deploy-all.sh
```

**Tiempo total**: 35-40 minutos

**Pasos individuales** (si prefieres control manual):
```bash
# Paso 1: Cluster GKE (12-15 min)
bash gcp-deploy-1-cluster.sh

# Paso 2: Cloud SQL (15 min)
bash gcp-deploy-2-database.sh

# Paso 3: ImÃ¡genes Docker (3-5 min)
bash gcp-deploy-3-docker-images.sh

# Paso 4: Aplicaciones K8s (2-3 min)
bash gcp-deploy-4-applications.sh

# Paso 5: VerificaciÃ³n (1 min)
bash gcp-deploy-5-verify.sh
```

**Obtener URL del frontend**:
```bash
kubectl get svc frontend-service -n frontend -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
# O desde Pulumi:
cd infrastructure-gcp-deploy
pulumi stack output frontend_url
```

---

## VerificaciÃ³n

**IMPORTANTE**: `kubectl` solo se usa para **observar** lo que Pulumi creÃ³. Todo se ejecuta desde tu laptop local.

```bash
# 1. Obtener credenciales del cluster (una sola vez)
az aks get-credentials --resource-group cpe-k8s-autoscaling-rg \
  --name cpe-k8s-autoscaling-aks --overwrite-existing

# 2. Ver recursos creados POR PULUMI (solo observaciÃ³n)
kubectl get pods --all-namespaces          # Ver pods
kubectl get svc --all-namespaces           # Ver servicios
kubectl get hpa -n backend                 # Ver autoscalers
kubectl get nodes -o wide                  # Ver nodos

# 3. Obtener URL del frontend (desde Pulumi, preferido)
cd infrastructure-k8s-deploy
pulumi stack output frontend_url
```

**kubectl NO crea infraestructura**, solo permite ver el estado del cluster remoto.

## ğŸŒ Acceso a la AplicaciÃ³n

### Frontend (React)
```bash
# Obtener IP pÃºblica
kubectl get svc -n frontend frontend-service

# Abrir en navegador
http://<EXTERNAL-IP>
```

## Autoscaling

### Horizontal Pod Autoscaler (HPA)
- **Backend**: 2-10 rÃ©plicas
  - Escala en CPU > 70%
  - Escala en RAM > 80%
- **Frontend**: 1-5 rÃ©plicas
  - Escala en CPU > 60%

### Cluster Autoscaler
- **Frontend pool**: 1-3 nodos (Standard_B2s)
- **Backend pool**: 1-5 nodos (Standard_B2s)
- **System pool**: 1 nodo fijo (Standard_B2s)

## Pruebas de Carga

### Desde la interfaz web
1. Abrir el frontend en el navegador
2. Usar el botÃ³n "Prueba de CPU" (genera carga en backend)
3. Usar "50 Peticiones SimultÃ¡neas" (genera carga de requests)

### Desde scripts
```bash
cd scripts

# Prueba moderada
python3 extreme-load.py --url http://<FRONTEND-IP> --duration 300

# Prueba intensa
python3 ultra-load.py --url http://<FRONTEND-IP>
```

### Monitorear autoscaling en tiempo real
```bash
# En una terminal
watch kubectl get hpa -n backend

# En otra terminal
watch kubectl get pods -n backend

# Ver mÃ©tricas de nodos
kubectl top nodes
kubectl top pods -n backend
```
---

## Destruir Infraestructura

**Importante**: Destruir en orden inverso al despliegue.

**Para GCP** (automatizado):
```bash
cd scripts
bash destroy-all.sh
```

**Para Azure** (manual):
```bash
# 1. Eliminar aplicaciones
cd infrastructure-k8s-deploy
pulumi destroy

# 2. Eliminar monitoreo (si lo desplegaste)
kubectl delete -f ../k8s/monitoring/prometheus-grafana.yaml

# 3. Eliminar base de datos (âš ï¸ esto borra los datos)
cd ../infrastructure-k8s-db
pulumi destroy

# 4. Eliminar cluster AKS
cd ../infrastructure-k8s-base
pulumi destroy
```

## CI/CD con GitHub Actions

Este proyecto incluye workflows automatizados de CI/CD que despliegan automÃ¡ticamente los cambios siguiendo el patrÃ³n **Micro-Stacks**.

### Workflows Disponibles

#### 1. **Backend CI/CD** (`.github/workflows/backend-ci-cd.yml`)
- **Trigger**: Push o PR a `backend/**`
- **Acciones**:
  - Construye imagen Docker del backend
  - Push a Google Artifact Registry (con retry automÃ¡tico)
  - Actualiza **solo** el deployment del backend en el stack `gcp-deploy`
  - Ejecuta health checks automÃ¡ticos
- **Tiempo estimado**: 3-5 minutos

#### 2. **Frontend CI/CD** (`.github/workflows/frontend-ci-cd.yml`)
- **Trigger**: Push o PR a `frontend/**`
- **Acciones**:
  - Construye imagen Docker del frontend
  - Push a Google Artifact Registry (con retry automÃ¡tico)
  - Actualiza **solo** el deployment del frontend en el stack `gcp-deploy`
  - Obtiene URL pÃºblica automÃ¡ticamente
- **Tiempo estimado**: 3-5 minutos

#### 3. **Infrastructure CI/CD** (`.github/workflows/infrastructure-ci-cd.yml`)
- **Trigger**: Push o PR a `infrastructure-gcp-*/**`
- **Acciones**:
  - **DetecciÃ³n automÃ¡tica**: Identifica quÃ© stack cambiÃ³ (base/db/deploy)
  - **Deploy condicional**: Solo despliega el stack modificado
  - **Dependencias**: Si cambia `gcp-base`, redespliega `gcp-deploy` automÃ¡ticamente
  - **EjecuciÃ³n manual**: Disponible via `workflow_dispatch` con dropdown
- **Tiempo estimado**: 5-15 minutos (segÃºn stack)

#### 4. **Load Testing** (`.github/workflows/load-test.yml`)
- **Trigger**: Manual via `workflow_dispatch`
- **Acciones**:
  - Ejecuta pruebas de carga contra el cluster GKE
  - Monitorea mÃ©tricas de autoscaling (HPA, pods, nodos)
  - Genera reporte detallado con resultados
- **ParÃ¡metros configurables**:
  - `target_url`: URL del frontend (auto-detecta si se omite)
  - `duration_seconds`: DuraciÃ³n de la prueba (default: 600s)
  - `workers`: NÃºmero de workers (default: 8)
  - `concurrent_per_worker`: Peticiones concurrentes (default: 150)

### ConfiguraciÃ³n de Secretos

Para usar los workflows de CI/CD, debes configurar **3 secretos** en tu repositorio de GitHub:

1. **`GCP_SA_KEY`** - JSON de service account de GCP
2. **`PULUMI_ACCESS_TOKEN`** - Token de acceso a Pulumi Cloud
3. **`DB_ADMIN_PASSWORD`** - Password de PostgreSQL en Cloud SQL


### CÃ³mo Usar

#### Despliegue AutomÃ¡tico de Backend

```bash
# 1. Haz cambios en el backend
vim backend/app.py

# 2. Commit y push
git add backend/
git commit -m "feat: Add new API endpoint"
git push

# 3. El workflow backend-ci-cd.yml se ejecuta automÃ¡ticamente
# - Construye nueva imagen Docker
# - Push a Artifact Registry
# - Actualiza deployment en GKE
# - Ejecuta health check
```

#### Despliegue AutomÃ¡tico de Frontend

```bash
# 1. Haz cambios en el frontend
vim frontend/src/App.jsx

# 2. Commit y push
git add frontend/
git commit -m "feat: Update UI design"
git push

# 3. El workflow frontend-ci-cd.yml se ejecuta automÃ¡ticamente
# - Construye nueva imagen Docker
# - Push a Artifact Registry
# - Actualiza deployment en GKE
# - Verifica URL pÃºblica
```

#### Despliegue Manual de Infraestructura

```bash
# OpciÃ³n 1: Via cÃ³digo (trigger automÃ¡tico)
vim infrastructure-gcp-base/__main__.py
git add infrastructure-gcp-base/
git commit -m "chore: Update node pool config"
git push

# OpciÃ³n 2: Via GitHub UI (manual)
# 1. Ve a Actions â†’ Infrastructure CI/CD
# 2. Click "Run workflow"
# 3. Selecciona stack: base/db/deploy/all
# 4. Click "Run workflow"
```

#### Ejecutar Load Test

```bash
# Via GitHub UI:
# 1. Ve a Actions â†’ GKE Autoscaling Load Test
# 2. Click "Run workflow"
# 3. Configura parÃ¡metros (o deja defaults)
# 4. Click "Run workflow"
# 5. Monitorea progreso en tiempo real
# 6. Revisa reporte en el summary del job
```

### Features de Seguridad y Confiabilidad

#### Retry Logic para Docker Push
```yaml
# Reintentos automÃ¡ticos con backoff exponencial
- Intento 1: Push directo
- Intento 2: Espera 10s y reintenta
- Intento 3: Espera 20s y reintenta
- Intento 4: Espera 40s y reintenta
```

#### Manejo de Cluster Unreachable
```yaml
# Limpieza automÃ¡tica de recursos huÃ©rfanos
env:
  PULUMI_K8S_DELETE_UNREACHABLE: "true"
```

#### Health Checks AutomÃ¡ticos
```yaml
# Backend: Port-forward + curl
- kubectl port-forward â†’ http://localhost:5000/health
# Frontend: LoadBalancer + curl
- curl http://<EXTERNAL-IP>/health
```

### Monitoreo de Workflows

Los workflows generan **summaries detallados** con informaciÃ³n Ãºtil:

- **Backend/Frontend CI/CD**:
  - Image URL en Artifact Registry
  - NÃºmero de rÃ©plicas (actual vs deseadas)
  - Status de deployment
  - Comandos para monitoreo manual

- **Infrastructure CI/CD**:
  - Stack desplegado
  - Cluster endpoints
  - Frontend URL pÃºblica
  - Comandos kubectl de verificaciÃ³n

- **Load Test**:
  - Estado inicial del cluster (nodos, pods, HPAs)
  - Estado post-carga (escalado observado)
  - Eventos de scaling recientes
  - UtilizaciÃ³n de recursos (CPU/Memoria)
  - Summary con verificaciÃ³n de criterios

## Autor

Christian PE  
Proyecto de demostraciÃ³n de IaC y Autoscaling

## Licencia

MIT License
